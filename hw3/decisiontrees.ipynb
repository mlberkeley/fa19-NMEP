{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implent your own decision tree/random forest!\n",
    "\n",
    "\n",
    "In this python notebook, you will create a basic decision tree on pandas data, and train a classifier on the Iris dataset. Then, you will implement a type of bagging and create a random forest classifier!\n",
    "\n",
    "First, import the required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then import and preview the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3  species\n",
       "0  5.1  3.5  1.4  0.2        0\n",
       "1  4.9  3.0  1.4  0.2        0\n",
       "2  4.7  3.2  1.3  0.2        0\n",
       "3  4.6  3.1  1.5  0.2        0\n",
       "4  5.0  3.6  1.4  0.2        0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data)\n",
    "df['species'] = iris.target \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have four features labeled 0, 1, 2, and 3. I believe these stand for the length and the width of the sepals and petals, in centimeters. I don't quite know which is which in the dataset (or what a sepal is) but it doesn't really matter. We want to use these four features to predict whether the species is one of three types of Iris plant, labeled 0, 1, or 2. \n",
    "\n",
    "Now, we split the dataset into training and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= .75\n",
    "train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "train = train.drop(['is_train'], axis = 1)\n",
    "test = test.drop(['is_train'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to implement some measure of disorder in a set of data. Implement either entropy ($\\sum_x -p(x)\\log x$) or GINI impurity discussed in class. The argument `data` is a pandas dataframe containing the features and labels of several data points. We calculate disorder based on the labels, or the last column of the data. Note: make sure that you make this function work for different data (i.e. your function should work for data of different dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disorder(data):\n",
    "    counter = {}\n",
    "    total = 0\n",
    "    for x in data.iloc[:,data.shape[1]-1]:\n",
    "        counter[x] = counter.get(x,0) + 1\n",
    "    for count in counter.values():\n",
    "        p = count/data.shape[0]\n",
    "        total += -(p*np.log(p)/.693)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a split function. This function takes in a dataset, and indices for a row and column. We then return two dataframes split on the `column`th feature. The left dataset should contain all of the data where the `column`th feature is greater or equal to the `column`th feature of the `row`th datapoint, and the right should contain the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_on_row_column(data, row, column):\n",
    "    left = data.loc[data.iloc[row, column] >= data.iloc[:, column]]\n",
    "    right = data.loc[data.iloc[row, column] < data.iloc[:, column]]\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to define our recursive tree class. During training, there are two cases for a node. If the data is all one label, the node is a leaf node, and we return this value during inference. If the data is not all the same label, we find the best split of the data by iterating through all of features and rows in the data.\n",
    "\n",
    "Inference takes in a row of a pandas dataframes and returns the predicted class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def train(self):\n",
    "        if disorder(self.data) == 0:\n",
    "            self.leaf = True\n",
    "            self.value = self.data.iloc[0, self.data.shape[1] - 1]\n",
    "            return\n",
    "        self.leaf = False\n",
    "        self.value = 420\n",
    "        min_entropy = -1\n",
    "        split_row = 0\n",
    "        split_col = 0\n",
    "        left = self.data\n",
    "        right = self.data\n",
    "        for col in range(self.data.shape[1] - 1):\n",
    "            for row in range(self.data.shape[0]):\n",
    "                l, r = split_on_row_column(self.data, row, col)\n",
    "                e = disorder(l)*l.shape[0] + disorder(r)*r.shape[0]\n",
    "                if min_entropy == -1 or e < min_entropy:\n",
    "                    min_entropy = e\n",
    "                    split_row = row\n",
    "                    split_col = col\n",
    "                    left = l\n",
    "                    right = r\n",
    "                    \n",
    "        self.split_row = split_row\n",
    "        self.split_col = split_col\n",
    "        self.left = Node(left)\n",
    "        self.right = Node(right)\n",
    "        self.left.train()\n",
    "        self.right.train()\n",
    "            \n",
    "   \n",
    "        \n",
    "    def inference(self, x):\n",
    "        if self.leaf:\n",
    "            return self.value\n",
    "        if self.data.iloc[self.split_row, self.split_col] >= x.iloc[self.split_col]:\n",
    "            return self.left.inference(x)\n",
    "        return self.right.inference(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now initialize and train a decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = Node(train)\n",
    "tree.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we don't check the training accuracy here (why?). We now want to validate our tree on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9705882352941176"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def validate(model, data):\n",
    "    ct = 0\n",
    "    corr = 0\n",
    "    for i in range(test.shape[0]):\n",
    "        data = test.iloc[i]\n",
    "        ct += 1\n",
    "        if model.inference(data) == data['species']:\n",
    "            corr += 1\n",
    "    return corr/ct\n",
    "\n",
    "validate(tree, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest!\n",
    "\n",
    "Now we will implement data bagging with a random forest! The set up is similar to a single tree. We pass in the data to the forest, along with hyperparameters `n` and `frac` which correspond to the number of trees and the fraction of the dataset to use in each bag. In the inference step we tally the number of votes from each decision tree and return the label with the most amount of votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Forest:\n",
    "    def __init__(self, data, n, frac):\n",
    "        self.data = data\n",
    "        self.n = n\n",
    "        self.frac = frac\n",
    "    \n",
    "    def train(self):\n",
    "        self.trees = []\n",
    "        for i in range(self.n):\n",
    "            print(\"Training tree\", str(i))\n",
    "            bag = self.data.sample(frac=self.frac)\n",
    "            tree = Node(bag)\n",
    "            tree.train()\n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    def inference(self, x):\n",
    "        counts = dict()\n",
    "        for tree in self.trees:\n",
    "            y = tree.inference(x)\n",
    "            counts[y] = counts.setdefault(y, 0) + 1\n",
    "        \n",
    "        maxCount = -1\n",
    "        maxVal = 0\n",
    "        \n",
    "        for val, count in counts.items():\n",
    "            if count > maxCount:\n",
    "                maxCount = count\n",
    "                maxVal = val\n",
    "        return maxVal        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tree 0\n",
      "Training tree 1\n",
      "Training tree 2\n",
      "Training tree 3\n",
      "Training tree 4\n",
      "Training tree 5\n",
      "Training tree 6\n",
      "Training tree 7\n",
      "Training tree 8\n",
      "Training tree 9\n",
      "Training tree 10\n",
      "Training tree 11\n",
      "Training tree 12\n",
      "Training tree 13\n",
      "Training tree 14\n",
      "Training tree 15\n",
      "Training tree 16\n",
      "Training tree 17\n",
      "Training tree 18\n",
      "Training tree 19\n",
      "Training tree 20\n",
      "Training tree 21\n",
      "Training tree 22\n",
      "Training tree 23\n",
      "Training tree 24\n",
      "Training tree 25\n",
      "Training tree 26\n",
      "Training tree 27\n",
      "Training tree 28\n",
      "Training tree 29\n"
     ]
    }
   ],
   "source": [
    "forest = Forest(train, 30, .5)\n",
    "forest.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9393939393939394"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate(forest, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
